{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nnsigh walkthrough\n",
    "https://nnsight.net/notebooks/tutorials/walkthrough/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "\n",
    "import nnsight\n",
    "from nnsight import NNsight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: nnsight\n",
      "Version: 0.2.21\n",
      "Summary: Package for interpreting and manipulating the internals of deep learning models.\n",
      "Home-page: https://github.com/ndif-team/nnsight\n",
      "Author: \n",
      "Author-email: Jaden Fiotto-Kaufman <jadenfk@outlook.com>\n",
      "License: \n",
      "Location: /home/ailab/python_venv/feature_circuits/lib/python3.11/site-packages\n",
      "Requires: accelerate, diffusers, einops, protobuf, pydantic, python-socketio, sentencepiece, tokenizers, torch, torchvision, transformers\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show nnsight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracing Context\n",
    "Everything within the tracing context operates on the intervention graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 5\n",
    "hidden_dims = 10\n",
    "output_size = 2\n",
    "\n",
    "net = torch.nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [\n",
    "            (\"layer1\", torch.nn.Linear(input_size, hidden_dims)),\n",
    "            (\"layer2\", torch.nn.Linear(hidden_dims, output_size)),\n",
    "        ]\n",
    "    )\n",
    ").requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (layer1): Linear(in_features=5, out_features=10, bias=True)\n",
       "  (layer2): Linear(in_features=10, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_model = NNsight(net)\n",
    "tiny_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random input\n",
    "input = torch.rand((1, input_size))\n",
    "\n",
    "with tiny_model.trace(input) as tracer:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5712, 0.0162]])\n"
     ]
    }
   ],
   "source": [
    "#output of the model as a whole\n",
    "with tiny_model.trace(input) as tracer:\n",
    "\n",
    "    output = tiny_model.output.save()\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2227,  0.2501,  0.1167,  0.1502, -0.1809, -0.3574,  0.5037,  0.4595,\n",
      "          0.2806, -0.3728]])\n"
     ]
    }
   ],
   "source": [
    "#Let’s access the output of the first layer\n",
    "with tiny_model.trace(input) as tracer:\n",
    "\n",
    "    l1_output = tiny_model.layer1.output.save()\n",
    "\n",
    "print(l1_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((tensor([[ 0.2227,  0.2501,  0.1167,  0.1502, -0.1809, -0.3574,  0.5037,  0.4595,\n",
      "          0.2806, -0.3728]]),), {})\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input):\n",
    "\n",
    "    l2_input = tiny_model.layer2.input.save()\n",
    "\n",
    "print(l2_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions, Methods, and Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input):\n",
    "\n",
    "    # Note we don't need to call .save() on the output,\n",
    "    # as we're only using its value within the tracing context.\n",
    "    l1_output = tiny_model.layer1.output\n",
    "\n",
    "    # We do need to save the argmax tensor however,\n",
    "    # as we're using it outside the tracing context.\n",
    "    l1_amax = torch.argmax(l1_output, dim=1).save()\n",
    "\n",
    "print(l1_amax[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6600)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Run the model with the given input. \n",
    "When the output of tiny_model.layer1 is computed, take its sum. \n",
    "Then do the same for tiny_model.layer2. \n",
    "Now that both of those are computed, add them and make sure \n",
    "not to delete this value as I wish to use it outside of the \n",
    "tracing context.\"\"\"\n",
    "with tiny_model.trace(input):\n",
    "\n",
    "    value = (tiny_model.layer1.output.sum() + tiny_model.layer2.output.sum()).save()\n",
    "\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nnsight' has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(total)\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtiny_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtracer\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Specify the function name and its arguments (in a comma-separated form) to add to the intervention graph\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_sum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnnsight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_sum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtiny_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtiny_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/python_venv/feature_circuits/lib/python3.11/site-packages/nnsight/contexts/Runner.py:41\u001b[0m, in \u001b[0;36mRunner.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"On exit, run and generate using the model whether locally or on the server.\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc_val, \u001b[38;5;167;01mBaseException\u001b[39;00m):\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_val\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mremote:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_server()\n",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(total)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tiny_model\u001b[38;5;241m.\u001b[39mtrace(\u001b[38;5;28minput\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tracer:\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Specify the function name and its arguments (in a comma-separated form) to add to the intervention graph\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     custom_sum \u001b[38;5;241m=\u001b[39m \u001b[43mnnsight\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m(tensor_sum, tiny_model\u001b[38;5;241m.\u001b[39mlayer1\u001b[38;5;241m.\u001b[39moutput)\u001b[38;5;241m.\u001b[39msave()\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m tiny_model\u001b[38;5;241m.\u001b[39mlayer1\u001b[38;5;241m.\u001b[39moutput\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28msum\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'nnsight' has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# Take a tensor and return the sum of its elements\n",
    "def tensor_sum(tensor):\n",
    "    flat = tensor.flatten()\n",
    "    total = 0\n",
    "    for element in flat:\n",
    "        total += element.item()\n",
    "\n",
    "    return torch.tensor(total)\n",
    "\n",
    "with tiny_model.trace(input) as tracer:\n",
    "\n",
    "    # Specify the function name and its arguments (in a comma-separated form) to add to the intervention graph\n",
    "    custom_sum = nnsight.apply(tensor_sum, tiny_model.layer1.output).save()\n",
    "    sum = tiny_model.layer1.output.sum()\n",
    "    sum.save()\n",
    "\n",
    "\n",
    "print(custom_sum, sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: tensor([[-0.5135, -0.2158, -0.3256, -0.1693,  0.0873,  0.7608, -0.5865,  0.5870,\n",
      "         -0.8724, -0.0315]])\n",
      "After: tensor([[ 0.0000, -0.2158, -0.3256, -0.1693,  0.0873,  0.7608, -0.5865,  0.5870,\n",
      "         -0.8724, -0.0315]])\n"
     ]
    }
   ],
   "source": [
    "# let’s set the first dimension of the first layer’s output to 0. \n",
    "# NNsight makes this really easy using the ‘=’ operator\n",
    "\n",
    "with tiny_model.trace(input):\n",
    "\n",
    "    # Save the output before the edit to compare.\n",
    "    # Notice we apply .clone() before saving as the setting operation is in-place.\n",
    "    l1_output_before = tiny_model.layer1.output.clone().save()\n",
    "\n",
    "    # Access the 0th index of the hidden state dimension and set it to 0.\n",
    "    tiny_model.layer1.output[:, 0] = 0\n",
    "\n",
    "    # Save the output after to see our edit.\n",
    "    l1_output_after = tiny_model.layer1.output.save()\n",
    "\n",
    "print(\"Before:\", l1_output_before)\n",
    "print(\"After:\", l1_output_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: tensor([[ 0.2227,  0.2501,  0.1167,  0.1502, -0.1809, -0.3574,  0.5037,  0.4595,\n",
      "          0.2806, -0.3728]])\n",
      "After: tensor([[ 0.2227,  0.2501,  0.1167,  0.1502, -0.1809, -0.3574,  0.5037,  0.4595,\n",
      "          0.2806,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "with tiny_model.trace(input):\n",
    "\n",
    "    # Save the output before the edit to compare.\n",
    "    # Notice we apply .clone() before saving as the setting operation is in-place.\n",
    "    l1_output_before = tiny_model.layer1.output.clone().save()\n",
    "\n",
    "    # Access the last index of the hidden state dimension and set it to 0.\n",
    "    tiny_model.layer1.output[:, hidden_dims -1] = 0\n",
    "\n",
    "    # Save the output after to see our edit.\n",
    "    l1_output_after = tiny_model.layer1.output.save()\n",
    "\n",
    "print(\"Before:\", l1_output_before)\n",
    "print(\"After:\", l1_output_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scan and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feature_circuits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
